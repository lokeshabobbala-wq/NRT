**LOKESWARA REDDY**  
**AWS DATA ENGINEER**  
Hyderabad, Telangana  
+91-8985702662 | lokeshbobbala@gmail.com | [LinkedIn Profile](#) | [GitHub Profile](#)  

---  

#### **SUMMARY**  
Experienced AWS Data Engineer with over 8 years of expertise in architecting and deploying scalable ETL pipelines, big data processing, and cloud-based data solutions. Proficient in AWS Glue, Lambda, DMS, Redshift, Snowflake, and PySpark, with a proven track record of optimizing workflows and delivering actionable insights. Adept in system design, data modeling, and ensuring seamless migrations from on-premises to cloud platforms to drive business outcomes.  

---  

#### **CORE COMPETENCIES**  
- **Cloud Platforms**: AWS Glue, Lambda, DMS, S3, EC2, Step Functions, Redshift, Athena, CodeCommit, RDS  
- **ETL & Data Pipelines**: PySpark, Python (Pandas, NumPy), SQL, Snowflake Data Warehouse, Data Migration  
- **Big Data Technologies**: Spark SQL, Snowpipe, Stream & Procedures, SCD1/SCD2 Logic  
- **Workflow Orchestration**: Jenkins, GitLab CI/CD, Airflow, Stonebranch, YAML Configurations  
- **Data Modeling & Optimization**: System Design, Database Optimization, Data Lakes, Data Marts  
- **Programming & Tools**: Python, R, SQL, Jupyter Notebook, VS Code, Git, SonarQube  

---  

#### **PROFESSIONAL EXPERIENCE**  

**AWS Data Engineer**  
**Birlasoft Pvt Ltd, Hyderabad**  
*10/2024 – Current*  
- Designed end-to-end scalable ETL pipelines using AWS Glue, Lambda, and Redshift to automate data workflows, reducing manual intervention by 40%.  
- Orchestrated multi-step AWS Step Functions workflows for data validation, transformation, and integration into Redshift, ensuring 99.9% pipeline uptime.  
- Developed Redshift views and dynamic Power BI dashboards, enabling real-time business insights and priority-based report refresh triggered by specific file loads.  
- Built audit and monitoring systems using PostgresSQL audit tables, improving data validation efficiency by 30%.  

**Special Achievements**:  
- Reduced ETL job execution time by 25% through optimization of Glue scripts.  
- Implemented robust security layers for file transmission using Secure File Gateway (SFG) integrated with AWS S3.  

---  

**Specialist - Data Engineering**  
**LTIMINDTREE, Hyderabad**  
*06/2023 – 10/2024*  
- Spearheaded the migration of ETL processes from Informatica PowerCenter to AWS Glue with PySpark, achieving 20% faster data processing.  
- Automated JSON data validation workflows and integrated error-handling mechanisms, ensuring 100% data accuracy in pipelines.  
- Transitioned SQL Server stored procedures to PostgreSQL using AWS Schema Conversion Tool (SCT), reducing database costs by 30%.  
- Delivered reusable ETL modules with parameterized code blocks, reducing redundancy by 40%.  

**Special Achievements**:  
- Improved maintainability and scalability of ETL workflows using modular Glue jobs orchestrated via AWS Step Functions.  
- Enhanced CI/CD pipelines with GitLab and SonarQube for code quality assurance.  

---  

**Senior Consultant – Data Engineering**  
**CAPGEMINI, Hyderabad**  
*02/2022 – 05/2023*  
- Automated data workflows from AWS Redshift to S3 using YAML configurations and integrated version control with GitHub.  
- Designed Snowflake pipelines leveraging Snowpipe, Streams, and Procedures to handle SCD1 and SCD2 logic for incremental and full loads.  
- Reduced data refresh time by 50% with time-triggered Snowflake procedures for real-time updates.  
- Deployed CI/CD workflows for Airflow DAGs, enabling seamless orchestration of data loads across environments.  

**Special Achievements**:  
- Optimized Snowflake procedures for data warehousing tasks, improving query performance by 30%.  

---  

**AWS Data Engineer**  
**Tata Consultancy Services, Hyderabad**  
*09/2016 – 02/2022*  
- Developed and deployed data lake pipelines on AWS Glue and S3, achieving 99.9% uptime and seamless integration with business-critical systems.  
- Migrated on-premises data from MySQL and IBM DB2 to AWS S3 using AWS DMS with Continuous Data Capture (CDC).  
- Designed scalable ETL workflows using AWS Step Functions, enabling real-time data transformation.  

**Special Achievements**:  
- Implemented advanced SCD logic for historical data tracking and enabled real-time analytics pipelines.  

---  

#### **EDUCATION**  
**PG Diploma in Data Science**  
Manipal Academy of Higher Education, Bangalore, Karnataka | *06/2019* | **CGPA: 8.6**  

**Bachelor of Technology in Computer Science**  
G. Pulla Reddy Engineering College, Kurnool | *04/2016* | **CGPA: 6.29**  

---  

#### **ACHIEVEMENTS**  
- State-level cricket player, showcasing leadership and teamwork skills.  

---  

#### **PROJECT SHOWCASE**  
**Optimizing Cloud-Based Data Workflows**  
- Migrated 50+ ETL workflows from on-premises systems to AWS Glue and Snowflake, reducing operational costs by 25%.  
- Designed scalable Glue jobs with PySpark for handling semi-structured data, improving data ingestion speed by 30%.  

**Automated Reporting System on AWS**  
- Developed an automated reporting system integrated with Power BI and AWS Redshift, reducing manual report generation time by 50%.  
- Built dynamic views and audit mechanisms to ensure data accuracy and timely updates for business-critical reports.  

---  

#### **ADDITIONAL HIGHLIGHTS**  
- **Certifications**: AWS Certified Solutions Architect – Associate, Snowflake SnowPro Core Certification  
- **Technical Blogs**: Published articles on optimizing AWS Glue pipelines and Snowflake performance tuning.  
- **Open Source Contribution**: Contributor to PySpark-based data transformation libraries.